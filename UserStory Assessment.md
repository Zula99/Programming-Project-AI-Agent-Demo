UserStory Assessment

US-31: SmartMirrorAgent core System ML based
As a demo factory operator I want an intelligent AI agent that can automatically crawl and mirror websites So that I can create high-quality demo versions with 90% visual fidelity

- Agent processes URLs through complete flow: Memory Check â†’ Reconnaissance â†’ Strategy - Selection â†’ Crawl â†’ Quality Assessment â†’ Mirror Build â†’ Learning Storage

- Maintains session statistics and performance tracking

- Supports both single URL and batch processing modes

- Provides comprehensive result reporting with processing times and quality metrics

- Stores and retrieves patterns from memory database for learning optimization

US-32: Site Reconnaissance System ML based
As a demo factory operator I want the agent to quickly analyze target websites So that it can select optimal crawling strategies based on site characteristics
- Completes reconnaissance analysis in under 10 seconds
- Detects site types: Banking, E-commerce, SPA (React/Angular/Vue), WordPress, News, Static HTML
- Identifies JavaScript frameworks and complexity levels
- Measures page load times and asset counts
- Recommends appropriate crawling strategy based on analysis
- Provides confidence scores for recommendations

US-33: Adaptive Crawling Strategies
As a demo factory operator I want multiple crawling strategies available So that the agent can handle different website technologies effectively
- Implements Basic HTTP strategy for static HTML sites

- Implements JavaScript Render strategy using Crawl4AI for dynamic content

- Implements Full Browser strategy with complete browser automation for complex SPAs

- Implements Hybrid strategy that adapts based on real-time quality feedback

- Switches strategies dynamically if quality drops below thresholds

- Tracks success rates and performance metrics per strategy

US-34: Quality Monitoring System
As a demo factory operator I want comprehensive quality assessment of crawled content So that I can ensure demo sites meet 90% visual fidelity standards
- Calculates Content Completeness score (35% weight) based on text volume and extraction success
- Calculates Asset Coverage score (25% weight) based on CSS, JS, images, and fonts downloaded
- Calculates Navigation Integrity score (20% weight) based on internal links and structure
- Calculates Visual Fidelity score (20% weight) based on layout and styling preservation
- Provides overall weighted quality score from 0.0 to 1.0
- Generates recommendations: Excellent (0.9-1.0), Good (0.8-0.89), Acceptable (0.7-0.79), Poor (0.6-0.69), Failed (<0.6)

US-35: Learning System with Pattern Storage
As a demo factory operator I want the agent to learn from successful crawls So that it  improves performance over time and reuses successful strategies

- Stores successful patterns (quality score â‰¥ 0.7) in SQLite database

- Records domain, site type, strategy used, quality metrics, and crawl configuration

- Finds similar patterns based on domain, frameworks, and site characteristics

- Recommends strategies with confidence scores based on historical success

- Applies time-based weighting to patterns (newer patterns weighted higher)

- Tracks improvement in success rates over time

US-36: FastAPI Backend Integration

As a frontend developer I want REST API endpoints for the AI agent system So that I can integrate crawling capabilities into the demo factory interface

- Provides POST /crawl endpoint to initiate crawling jobs

- Provides GET /status/{run_id} endpoint to check crawl progress

- Provides GET /results/{run_id} endpoint to retrieve crawl results

- Supports background task processing for non-blocking operations

- Includes CORS configuration for frontend integration

- Returns appropriate HTTP status codes and error messages

US-37: Multi-Strategy Site Type Handling

As a demo factory operator I want specialized handling for different site types So that banking, e-commerce, and SPA sites are crawled with appropriate methods

- Banking sites automatically use JavaScript Render or Full Browser strategies

- E-commerce sites handle dynamic product catalogs and shopping cart functionality

- React/Angular/Vue SPAs use Full Browser strategy for complete rendering

- WordPress sites optimize for CMS structure and content extraction

- News sites prioritize content extraction and article structure

- Static HTML sites use fast Basic HTTP strategy


US-38: Real-time Quality Adaptation
As a demo factory operator I want the agent to adapt crawling parameters in real-time So that quality issues are detected and corrected during the crawling process
- Monitors quality metrics during crawling process

- Adjusts crawling parameters (delays, timeouts, rendering settings) based on quality feedback

- Switches to fallback strategies if quality drops below 0.6

- Provides quality checkpoints throughout crawling process

- Stops crawling early if quality cannot be improved

- Logs adaptation decisions for learning system

US:39 - Batch Processing and Statistics

As a demo factory operator I want to process multiple URLs simultaneously So that I can efficiently create demos for multiple client websites
- Processes multiple URLs in sequence with configurable delays

- Provides aggregate statistics across all processed URLs

- Calculates batch success rate and average quality scores

- Tracks strategy usage distribution across batch

- Provides performance grading against 90% targets

- Generates comprehensive batch reports with individual URL results

US-40:  Performance Targets and Monitoring
As a demo factory operator I want the agent to meet specific performance targets So that the system is efficient and meets quality standards
- Reconnaissance completes in under 10 seconds per URL

- Strategy selection completes in under 5 seconds

- Full crawling completes within 5-30 minutes depending on site size

- Mirror building completes in under 5 minutes

- Achieves 90% success rate across all site types

- Achieves 90% average quality score across processed sites

- Provides real-time performance monitoring and target achievement tracking






### EPIC-01: Core Crawling Infrastructure (COMPLETED)
**Status:**  DONE  
**Description:** Foundational crawling and mirror generation capabilities for creating static demo websites

**Completed User Stories:**
- Basic web crawling with Crawl4AI AsyncWebCrawler
- Static mirror generation with offline asset localization
- Domain-agnostic mirror builder (generic for any website)
- Two-round asset fetching (HTML assets first, then CSS dependencies)
- URL rewriting and localization for offline browsing
- Basic quality scoring architecture framework

**Technical Achievements:**
- Crawl4AI integration for JavaScript rendering
- Asset downloading and localization pipeline
- CSS dependency resolution and @import handling
- Folder structure matching URL hierarchy
- Working demo: NAB bank crawler (80 pages, 0.6s delays)

**Current Limitations:**
- Windows encoding issues with Unicode characters
- Fixed crawling strategies (no dynamic adaptation)
- No learning or pattern recognition
- Manual configuration required per site

### EPIC-02: Production Deployment & Reliability (FUTURE)
**Status:**  CRITICAL  
**Description:** Address critical Windows encoding issues and production deployment requirements

**Future User Stories:**

**US-044: Docker Deployment Solution** (COMPLETED)
As a demo factory operator I want the system to run in Docker containers So that Windows encoding issues are eliminated and deployment is consistent across platforms
- Eliminates Windows path length limits causing content loss
- Fixes Windows charmap codec errors with Unicode characters  
- Provides UTF-8 encoding by default for all operations
- Enables consistent cross-platform deployment
- Supports easy demo deployment: `docker run smart-mirror-agent nab.com.au`

**US-045: Content Deduplication System**
As a demo factory operator I want the system to detect and skip duplicate content So that demos contain only unique, valuable content
- Implements text similarity detection using cosine similarity
- Detects URL pattern duplicates (e.g., /product/123 vs /product/456)
- Uses content hash comparison for exact duplicates
- Identifies template-based pages with different data
- Improves demo quality by focusing on diverse content

**US-046: Dynamic Stopping Conditions**
As a demo factory operator I want intelligent crawling that stops based on quality metrics So that the system achieves optimal coverage without arbitrary page limits
- Replaces fixed page limits with quality-based stopping
- Implements section coverage threshold (90% of main sections)
- Stops when quality plateaus for 30+ consecutive pages
- Early stopping when target quality score achieved
- Monitors content diversity and stops when becoming repetitive

### EPIC-03: Search & AI Integration (FUTURE)
**Status:**  ENHANCEMENT  
**Description:** Add OpenSearch indexing and chatbot capabilities to enhance demo value

**US-047: OpenSearch Integration**
As a demo user I want semantic search capabilities across all crawled content So that I can find information more effectively than the original site navigation
- Indexes all crawled content in OpenSearch for semantic search
- Provides custom search bar that surpasses original site navigation
- Implements full-text search with relevance ranking
- Supports faceted search and content filtering
- Creates search-enhanced demo experience

**US-048: Chatbot Integration**
As a demo user I want an AI chatbot embedded in demo sites So that I can interact with site content intelligently
- Embeds AI assistant in all demo sites
- Provides context-aware responses based on crawled content
- Supports natural language queries about site information
- Integrates with OpenSearch for comprehensive content access
- Enhances demo presentation value for client meetings

### EPIC-04: Hybrid AI Agent System (CORE IMPLEMENTATION)
**Status:**  IN PROGRESS  
**Description:** True AI Agent system that layers AI API calls on existing foundation for intelligent decision making

**Existing User Stories (To Complete):**
- US-31: SmartMirrorAgent core System ML based (20% complete)
- US-35: Learning System with Pattern Storage (0% complete)
- US-36: FastAPI Backend Integration (0% complete)
- US-38: Real-time Quality Adaptation (0% complete)
- US-39: Batch Processing and Statistics (0% complete)
- US-40: Performance Targets and Monitoring (30% complete)
- US-33: Adaptive Crawling Strategies (40% complete)

**New AI-Powered User Stories:**

**US-049: AI Content Classification Layer**
As a demo factory operator I want AI-powered content worthiness assessment So that the system intelligently selects the most demo-valuable pages
- Replaces rigid URL filtering with AI content analysis
- Analyzes page content for client demonstration value
- Provides confidence scores and reasoning for page selection decisions
- Falls back to heuristic classification if AI fails
- Learns from successful demo outcomes to improve classification

**US-050: AI Strategy Optimization Layer**
As a demo factory operator I want AI-enhanced crawling strategy refinement So that the system optimizes parameters for maximum demo quality
- Uses AI to refine base strategies from pattern matching
- Optimizes max_pages, request_gap, and JS rendering settings per site
- Suggests priority URL patterns based on site analysis
- Combines algorithmic speed with AI intelligence
- Provides reasoning for strategy adjustments

**US-051: AI Site Analysis Layer**  
As a demo factory operator I want intelligent site characteristic detection So that the system understands website structure and technology stack
- Combines heuristic detection with AI analysis of site characteristics
- Detects CMS, frameworks, and site complexity automatically
- Identifies optimal crawling approaches per technology stack
- Provides comprehensive site fingerprinting for strategy selection
- Maintains reliability through hybrid approach (AI + algorithms)

**US-052: Hybrid Architecture Implementation**
As a system architect I want a reliable hybrid AI system So that we get AI intelligence with algorithmic reliability
- Implements AI API integration with fallback to heuristics
- Ensures cost efficiency by using AI only where it adds most value
- Provides incremental AI migration capability
- Maintains system reliability during AI service outages
- Combines speed of algorithms with intelligence of AI decision making

**Implementation Phases:**
- **Phase 1**: AI Content Classification Layer (US-049)
- **Phase 2**: AI Strategy Optimization Layer (US-050)  
- **Phase 3**: AI Site Analysis Layer (US-051)
- **Phase 4**: Complete Hybrid System Integration (US-052)

**Success Criteria:**
- 90% demo mirror quality score across all site types
- 90% important site coverage through intelligent content discovery
- True AI Agent functionality using LLM APIs for decisions
- Learning improvement in success rates over time
- Reliable fallback during AI service issues

**US-57: Set Up and Configure Reverse Proxy** âœ… COMPLETED
As a demo factory operator, I want to set up a reverse proxy that dynamically forwards requests to any target site so that I can easily inject our overlay without needing to create static mirrors.
- âœ… The reverse proxy routes incoming requests to the specified target site based on a configurable target URL
- ðŸ”„ The proxy supports HTML response modification for search bar and chatbot overlay injection (ready for implementation)
- âœ… We can change the target site easily without restarting the proxy via `/auto-configure` endpoint
- âœ… The proxy operates with minimal latency overhead and includes security measures like CSP removal and CORS handling
- âœ… Docker integration allows automatic proxy startup on `docker-compose up`
- âœ… Auto-configuration integration triggers when crawler completes successfully
- âœ… Universal URL rewriting ensures proper styling and navigation across all site types

**US-56: Injecting Search Bar with Indexed Data**
As a demo factory operator, I want to inject a search bar into the proxied site that uses the indexed data from the scrape so that users can search the mirrored content directly.
- We need to ensure the search bar appears on every proxied page at a predefined location in the DOM.
- The search bar must be connected to the indexed data gathered from the site so that all search queries return results from the scraped content.
- We need to verify that when a user enters a query, the search bar returns accurate results from the scraped index and displays them properly.
- The injected search functionality should not noticeably slow down the loading or performance of the proxied site.